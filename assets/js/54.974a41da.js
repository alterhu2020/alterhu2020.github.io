(window.webpackJsonp=window.webpackJsonp||[]).push([[54],{318:function(a,e,r){"use strict";r.r(e);var s=r(6),t=Object(s.a)({},function(){var a=this,e=a.$createElement,r=a._self._c||e;return r("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[r("h2",{attrs:{id:"scrapy爬虫配置"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#scrapy爬虫配置","aria-hidden":"true"}},[a._v("#")]),a._v(" Scrapy爬虫配置")]),a._v(" "),r("h2",{attrs:{id:"_1-开发环境"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_1-开发环境","aria-hidden":"true"}},[a._v("#")]),a._v(" 1. 开发环境")]),a._v(" "),r("h3",{attrs:{id:"_1-1-需要安装如下必需的开发包：pipenv-类库包如下："}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-需要安装如下必需的开发包：pipenv-类库包如下：","aria-hidden":"true"}},[a._v("#")]),a._v(" 1.1 需要安装如下必需的开发包："),r("code",[a._v("pipenv")]),a._v(",类库包如下：")]),a._v(" "),r("div",{staticClass:"language- extra-class"},[r("pre",{pre:!0,attrs:{class:"language-text"}},[r("code",[a._v("$ pip install pipenv\n$ pipenv install scrapy scrapyd-client\n$ pipenv install requests pymysql beautifulsoup4 lxml js2py selenium  \n")])])]),r("ul",[r("li",[a._v("数据库主机、数据库名称、用户名、密码等信息在"),r("code",[a._v("settings.py")]),a._v("文件中配置；")]),a._v(" "),r("li",[a._v("配置好数据库后，cmd进入程序所在目录，运行`scrapy crawl 项目名称即可；")]),a._v(" "),r("li",[a._v("使用"),r("code",[a._v("scrapyd-client")]),a._v("中的"),r("code",[a._v("scrapyd-deploy")]),a._v("命令行工具可以将脚本部署到指定的"),r("code",[a._v("scrapyd")]),a._v("服务上；")])]),a._v(" "),r("h3",{attrs:{id:"_1-2-配置对应的scrapy-cfg文件中的scrapyd服务器-如果使用下面的gerapy则不需要配置这个部分-该部分主要是为了scrapyd-deploy使用："}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-配置对应的scrapy-cfg文件中的scrapyd服务器-如果使用下面的gerapy则不需要配置这个部分-该部分主要是为了scrapyd-deploy使用：","aria-hidden":"true"}},[a._v("#")]),a._v(" 1.2 配置对应的"),r("code",[a._v("scrapy.cfg")]),a._v("文件中的"),r("code",[a._v("scrapyd")]),a._v("服务器(如果使用下面的gerapy则不需要配置这个部分),该部分主要是为了"),r("code",[a._v("scrapyd-deploy")]),a._v("使用：")]),a._v(" "),r("div",{staticClass:"language- extra-class"},[r("pre",{pre:!0,attrs:{class:"language-text"}},[r("code",[a._v("[deploy:cvr_news]\n# url = http://localhost:6800/\n# project = spider_test\n# username = deployer\n# password = eaafbbdbe1494810b48a90651xe3452cd95f\n")])])]),r("h2",{attrs:{id:"_2-分布式脚本执行部署环境"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_2-分布式脚本执行部署环境","aria-hidden":"true"}},[a._v("#")]),a._v(" 2. 分布式脚本执行部署环境")]),a._v(" "),r("blockquote",[r("blockquote",[r("blockquote",[r("p",[a._v("参考文档: "),r("a",{attrs:{href:"https://blog.csdn.net/qq_38003892/article/details/80427278",target:"_blank",rel:"noopener noreferrer"}},[a._v("scrapy部署， Gerapy 分布式爬虫管理部署使用"),r("OutboundLink")],1)])])])]),a._v(" "),r("blockquote",[r("blockquote",[r("blockquote",[r("p",[a._v("参考文档： "),r("a",{attrs:{href:"https://www.cnblogs.com/sxqjava/p/10037731.html",target:"_blank",rel:"noopener noreferrer"}},[a._v("gerapy+scrapyd组合管理分布式爬虫"),r("OutboundLink")],1)])])])]),a._v(" "),r("h3",{attrs:{id:"_2-1-gerapy服务器环境配置"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-gerapy服务器环境配置","aria-hidden":"true"}},[a._v("#")]),a._v(" 2.1 "),r("code",[a._v("gerapy")]),a._v("服务器环境配置")]),a._v(" "),r("ul",[r("li",[a._v("安装"),r("code",[a._v("scrapy")]),a._v("部署服务,也是一个远程服务。是运行"),r("code",[a._v("scrapy")]),a._v("爬虫的服务端程序,它支持以"),r("code",[a._v("http")]),a._v("接口命令方式发布、删除、启动、停止爬虫程序。")]),a._v(" "),r("li",[a._v("在电脑任意位置新建一个文件夹,打开cmd，进入到这个文件夹下，输入命令"),r("code",[a._v("gerapy init")]),a._v(".安装"),r("code",[a._v("Gerapy")]),a._v(".\n初始化完成后会生成一个文件夹"),r("code",[a._v("gerapy")]),a._v("，该文件夹下面会生成一个"),r("code",[a._v("projects")]),a._v("文件夹.进入到该创建的"),r("code",[a._v("gerapy")]),a._v("文件夹下，再输入"),r("code",[a._v("gerapy migrate")]),a._v("完成"),r("code",[a._v("gerapy")]),a._v("初始化工作. 将scrapy脚本项目放到"),r("code",[a._v("projects")]),a._v("目录下,利用"),r("code",[a._v("gerapy runserver")]),a._v("，启动"),r("code",[a._v("gerapy")]),a._v(". 刷新即可看到部署的脚本。")])]),a._v(" "),r("div",{staticClass:"language- extra-class"},[r("pre",{pre:!0,attrs:{class:"language-text"}},[r("code",[a._v("$ mkdir spider-gerapy\n$ cd spider-gerapy\n$ pip install gerapy\n$ gerapy init\n$ cd gerapy\n$ gerapy migrate \n初始化数据库\n$ gerapy createsuperuser\n创建超级用户，用于登录界面\n$ gerapy runserver\n后台静默运行gerapy服务,注意一定要切换到新创建的gerapy目录下面\n$ nohup gerapy runserver 0.0.0.0:6000 &\n")])])]),r("h3",{attrs:{id:"_2-2-scrapyd脚本执行机器环境配置"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-scrapyd脚本执行机器环境配置","aria-hidden":"true"}},[a._v("#")]),a._v(" 2.2 "),r("code",[a._v("scrapyd")]),a._v("脚本执行机器环境配置")]),a._v(" "),r("ul",[r("li",[r("code",[a._v("scrapyd")]),a._v("不需要设置目录，可以同时管理多个爬虫,每个爬虫还可以有多个版本：")])]),a._v(" "),r("div",{staticClass:"language- extra-class"},[r("pre",{pre:!0,attrs:{class:"language-text"}},[r("code",[a._v('$ pip install scrapyd\n一般安装在类似目录： `/usr/local/lib/python3.8/dist-packages/scrapyd`\n$ find / -name "default_scrapyd.conf"\n$ nano default_scrapyd.conf\n1. 修改scrapyd服务的端口号，默认端口是`6800`\n2. 设置远程访问端口可以放行（`bind_address`由`127.0.0.1`改成0.0.0.0）\n3. 修改日志存放目录\n')])])]),r("p",[a._v("上面需要修改的配置文件内容如下：")]),a._v(" "),r("div",{staticClass:"language- extra-class"},[r("pre",{pre:!0,attrs:{class:"language-text"}},[r("code",[a._v("eggs_dir    = /www/spider/eggs\nlogs_dir    = /logs\nitems_dir   = /www/spider/items\n\nbind_address = 0.0.0.0\nhttp_port   = 6800\n\nusername = deployer\npassword = eaafbbdbe1494810b48a9065152cd95f245dz\n")])])]),r("ul",[r("li",[a._v("上面的配置修改成功后执行以下脚本运行"),r("code",[a._v("scrapyd")]),a._v("后台启动服务：")])]),a._v(" "),r("div",{staticClass:"language- extra-class"},[r("pre",{pre:!0,attrs:{class:"language-text"}},[r("code",[a._v("$ nohup scrapyd &\n")])])]),r("ul",[r("li",[a._v("脚本运行端需要安装对应的"),r("code",[a._v("scrapy")]),a._v("开发环境中提到的所有库，执行如下命令安装:")])]),a._v(" "),r("div",{staticClass:"language- extra-class"},[r("pre",{pre:!0,attrs:{class:"language-text"}},[r("code",[a._v("pip install scrapy requests pymysql beautifulsoup4 lxml js2py selenium   \n")])])])])},[],!1,null,null,null);e.default=t.exports}}]);